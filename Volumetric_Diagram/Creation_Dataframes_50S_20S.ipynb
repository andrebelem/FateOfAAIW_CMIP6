{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "121318ab"
      },
      "source": [
        "## Notebook Overview\n",
        "\n",
        "This notebook processes oceanographic data for historical and future climate scenarios (SSP585 and SSP370) within the 30S-50S latitude band, focusing on the depth interval from 300m to 1500m.\n",
        "\n",
        "For each scenario and model, the following steps are performed:\n",
        "\n",
        "1.  **Data Loading**: NetCDF files from the 'Medias_nc\\\\50S_20S' folder are opened using xarray.\n",
        "2.  **Variable Conversion**:\n",
        "    *   Depth ('lev') is converted to pressure ('p') using `gsw.p_from_z`.\n",
        "    *   Preformed salinity ('so') is converted to absolute salinity using `gsw.SA_from_Sstar`.\n",
        "3.  **Depth Selection**: The data is sliced to retain only the depth range between 300m and 1500m.\n",
        "4.  **Volume Calculation**: A 'vol' variable is created, representing the volume for every 5m depth interval, based on the 'area' variable.\n",
        "5.  **Interval Binning**:\n",
        "    *   Temperature ('thetao') data is binned into 0.2°C intervals from -2°C to 20°C.\n",
        "    *   Salinity ('so') data is binned into 0.02 intervals from 33 to 37.\n",
        "6.  **Data Aggregation**: The total volume ('vol') is summed for each unique combination of binned temperature and salinity.\n",
        "7.  **Mean Calculation**: The midpoint (average) of the temperature and salinity bins are calculated and added as new columns.\n",
        "8.  **DataFrame Restructuring**: The resulting aggregated data is formatted into a pandas DataFrame with 'thetao', 'so', and 'vol' columns.\n",
        "9.  **Data Saving**: Each processed DataFrame is saved as a Parquet file in the 'Dataframes_50S_20S' folder, with a filename derived from the original NetCDF file."
      ],
      "id": "121318ab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8e83688-884b-4354-a06e-d6d54a8e0fcd",
      "metadata": {
        "id": "a8e83688-884b-4354-a06e-d6d54a8e0fcd"
      },
      "outputs": [],
      "source": [
        "import pygmt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import gsw"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating an historical dataframe\n"
      ],
      "metadata": {
        "id": "9VMdevuGe5vi"
      },
      "id": "9VMdevuGe5vi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5e7400a-d233-4a07-8b91-6f9787561f09",
      "metadata": {
        "id": "f5e7400a-d233-4a07-8b91-6f9787561f09",
        "outputId": "e913f255-afcd-4832-d7d8-194f8b436e18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:28: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: CMIP.CAMS.CAMS-CSM1-0.historical\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: CMIP.CNRM-CERFACS.CNRM-ESM2-1.historical\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:28: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: CMIP.IPSL.IPSL-CM6A-LR.historical\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:28: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: CMIP.MIROC.MIROC6.historical\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:28: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: CMIP.NCAR.CESM2.historical\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:28: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\3286934739.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: CMIP.NOAA-GFDL.GFDL-ESM4.historical\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Folder where the files are located\n",
        "pasta = 'Medias_nc\\\\50S_20S'\n",
        "\n",
        "# Folder to save the files\n",
        "saves = 'Dataframes_50S_20S'\n",
        "\n",
        "# List the files in the folder\n",
        "arquivos = os.listdir(pasta)\n",
        "\n",
        "# Loop through the files\n",
        "for arquivo in arquivos:\n",
        "    if \"historical\" in arquivo:\n",
        "        caminho_arquivo = os.path.join(pasta, arquivo)\n",
        "\n",
        "        # Open the file using xarray\n",
        "        ds = xr.open_dataset(caminho_arquivo)\n",
        "\n",
        "        # Convert Depth to pressure.\n",
        "        ds['p'] = gsw.p_from_z(-ds['lev'], ds['lat'])\n",
        "\n",
        "        # Convert preformed salinity to absolute salinity.\n",
        "        ds['so'] = gsw.SA_from_Sstar(ds['so'], ds['p'], ds['lon'],ds['lat'])\n",
        "\n",
        "        # Select the depth interval\n",
        "        ds_lev = ds.sel(lev=slice(300, 1500))\n",
        "\n",
        "        if 'lev_bnds' in ds_lev:\n",
        "            ds_lev = ds_lev.drop('lev_bnds')\n",
        "\n",
        "        if 'p' in ds_lev:\n",
        "            ds_lev = ds_lev.drop('p')\n",
        "\n",
        "        # Create the volume variable, according to the area for every 5m\n",
        "        ds_lev[\"vol\"] = 5 * ds_lev[\"area\"]\n",
        "\n",
        "        # Create the list for temperature intervals\n",
        "        lista_temp = []           # Create an empty list\n",
        "        i = -2                    # Define a minimum for temperature\n",
        "        lista_temp.append(i)      # Add this minimum to the list\n",
        "        while round(i, 2) < 20:   # Define a maximum for temperature, round is just to ensure 19.999 becomes 20.\n",
        "            i += 0.2\n",
        "            lista_temp.append(round(i, 2))   # round to ensure two decimal places and not e.g.: 2.400002.\n",
        "\n",
        "        # Create the list for salinity intervals --> Same considerations as for the temperature list\n",
        "        lista_sal = []\n",
        "        i=33\n",
        "        lista_sal.append(i)\n",
        "        while round(i, 3) < 37:\n",
        "            i+=0.02\n",
        "            lista_sal.append(round(i, 3))\n",
        "\n",
        "        # Create a dataframe to store\n",
        "        df_final = pd.DataFrame()\n",
        "\n",
        "        df = ds_lev.to_dataframe().dropna().reset_index()\n",
        "\n",
        "        # Apply pd.cut with defined limits.\n",
        "        cut_temp = pd.cut(df['thetao'], bins=lista_temp, include_lowest=True)   # Bins separate into 1-1.02; 1.02-1.04 ...\n",
        "        cut_salin = pd.cut(df['so'], bins=lista_sal, include_lowest=True)       # Bins separate into 1-1.002; 1.002-1.004 ...\n",
        "\n",
        "        # Group data by category intersections.\n",
        "        agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n",
        "\n",
        "        # Concatenate my data into a final dataframe\n",
        "        df_final = pd.concat([df_final, agrupado], ignore_index=True)\n",
        "\n",
        "        # Create empty lists\n",
        "        thetao_medias = []\n",
        "        so_medias = []\n",
        "\n",
        "        # Calculate interval averages and add to lists\n",
        "        for _, row in df_final.iterrows():\n",
        "            thetao_medias.append(row['thetao'].mid)\n",
        "            so_medias.append(row['so'].mid)\n",
        "\n",
        "        # Add lists as new columns to df_agrupado\n",
        "        df_final['thetao_media'] = thetao_medias\n",
        "        df_final['so_media'] = so_medias\n",
        "\n",
        "        df_final = df_final[[\"thetao_media\", \"so_media\", \"vol\"]]\n",
        "\n",
        "        # Rename\n",
        "        df_final.rename(columns={\"thetao_media\": \"thetao\", \"so_media\": \"so\"}, inplace=True)\n",
        "\n",
        "        # Extract the base file name (without path)\n",
        "        nome_base = os.path.basename(arquivo)\n",
        "\n",
        "        # Extract the relevant part of the name to use as DataFrame name\n",
        "        nome_partes = nome_base.split('.')\n",
        "        nome_dataframe = '.'.join(nome_partes[0:4])\n",
        "\n",
        "        # Define the output path for the parquet file based on the DataFrame name\n",
        "        caminho_saida = os.path.join(saves, f\"{nome_dataframe}.parquet\")\n",
        "\n",
        "        # Save the DataFrame in parquet format\n",
        "        df_final.to_parquet(caminho_saida)\n",
        "\n",
        "        print('Processing Completed: {}'.format(nome_dataframe))\n",
        "        # Close the xarray dataset\n",
        "        ds.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be68a653-a322-4245-88ab-ae0d092026a1",
      "metadata": {
        "id": "be68a653-a322-4245-88ab-ae0d092026a1"
      },
      "source": [
        "## Creating an SSP585 dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f17f076-e6e4-4be5-9a44-6a3f4287a7ab",
      "metadata": {
        "id": "2f17f076-e6e4-4be5-9a44-6a3f4287a7ab",
        "outputId": "7dfde2c0-e602-4a5d-f8c4-623c77458651"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.CAMS.CAMS-CSM1-0.ssp585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.CNRM-CERFACS.CNRM-ESM2-1.ssp585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.IPSL.IPSL-CM6A-LR.ssp585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.MIROC.MIROC6.ssp585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.NCAR.CESM2.ssp585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_30936\\477934789.py:62: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.NOAA-GFDL.GFDL-ESM4.ssp585\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Folder where the files are located\n",
        "pasta = 'Medias_nc\\\\50S_20S'\n",
        "\n",
        "# Folder to save the files\n",
        "saves = 'Dataframes_50S_20S'\n",
        "\n",
        "# List the files in the folder\n",
        "arquivos = os.listdir(pasta)\n",
        "\n",
        "# Loop through the files\n",
        "for arquivo in arquivos:\n",
        "    if \"ssp585\" in arquivo:\n",
        "        caminho_arquivo = os.path.join(pasta, arquivo)\n",
        "\n",
        "        # Open the file using xarray\n",
        "        ds = xr.open_dataset(caminho_arquivo)\n",
        "\n",
        "        # Convert Depth to pressure.\n",
        "        ds['p'] = gsw.p_from_z(-ds['lev'], ds['lat'])\n",
        "\n",
        "        # Convert preformed salinity to absolute salinity.\n",
        "        ds['so'] = gsw.SA_from_Sstar(ds['so'], ds['p'], ds['lon'],ds['lat'])\n",
        "\n",
        "        # Select the depth interval from 500 to 1500m\n",
        "        ds_lev = ds.sel(lev=slice(300, 1500))\n",
        "\n",
        "        # Create the volume variable, according to the area for every 5m\n",
        "        ds_lev[\"vol\"] = 5 * ds_lev[\"area\"]\n",
        "\n",
        "        if 'lev_bnds' in ds_lev:\n",
        "            ds_lev = ds_lev.drop('lev_bnds')\n",
        "\n",
        "        if 'p' in ds_lev:\n",
        "            ds_lev = ds_lev.drop('p')\n",
        "\n",
        "        # Create the list for temperature intervals\n",
        "        lista_temp = []\n",
        "        i = -2\n",
        "        lista_temp.append(i)\n",
        "        while round(i, 2) < 20:\n",
        "            i += 0.2\n",
        "            lista_temp.append(round(i, 2))\n",
        "\n",
        "        # Create the list for salinity intervals\n",
        "        lista_sal = []\n",
        "        i=33\n",
        "        lista_sal.append(i)\n",
        "        while round(i, 3) < 37:\n",
        "            i+=0.02\n",
        "            lista_sal.append(round(i, 3))\n",
        "\n",
        "        # Create a dataframe to store\n",
        "        df_final = pd.DataFrame()\n",
        "\n",
        "        df = ds_lev.to_dataframe().dropna().reset_index()\n",
        "\n",
        "        # Apply pd.cut with defined limits\n",
        "        cut_temp = pd.cut(df['thetao'], bins=lista_temp, include_lowest=True)\n",
        "        cut_salin = pd.cut(df['so'], bins=lista_sal, include_lowest=True)\n",
        "\n",
        "        # Group data by category intersections\n",
        "        agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n",
        "\n",
        "        # Concatenate my data into a final dataframe\n",
        "        df_final = pd.concat([df_final, agrupado], ignore_index=True)\n",
        "\n",
        "        # Create empty lists\n",
        "        thetao_medias = []\n",
        "        so_medias = []\n",
        "\n",
        "        # Calculate interval averages and add to lists\n",
        "        for _, row in df_final.iterrows():\n",
        "            thetao_medias.append(row['thetao'].mid)\n",
        "            so_medias.append(row['so'].mid)\n",
        "\n",
        "        # Add lists as new columns to df_agrupado\n",
        "        df_final['thetao_media'] = thetao_medias\n",
        "        df_final['so_media'] = so_medias\n",
        "\n",
        "        df_final = df_final[[\"thetao_media\", \"so_media\", \"vol\"]]\n",
        "\n",
        "        # Rename\n",
        "        df_final.rename(columns={\"thetao_media\": \"thetao\", \"so_media\": \"so\"}, inplace=True)\n",
        "\n",
        "        # Extract the base file name (without path)\n",
        "        nome_base = os.path.basename(arquivo)\n",
        "\n",
        "        # Extract the relevant part of the name to use as DataFrame name\n",
        "        nome_partes = nome_base.split('.')\n",
        "        nome_dataframe = '.'.join(nome_partes[0:4])\n",
        "\n",
        "        # Define the output path for the parquet file based on the DataFrame name\n",
        "        caminho_saida = os.path.join(saves, f\"{nome_dataframe}.parquet\")\n",
        "\n",
        "        # Save the DataFrame in parquet format\n",
        "        df_final.to_parquet(caminho_saida)\n",
        "\n",
        "        print('Processing Completed: {}'.format(nome_dataframe))\n",
        "        # Close the xarray dataset\n",
        "        ds.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b636942-0f49-4714-b9ec-e49b9b1b7638",
      "metadata": {
        "id": "0b636942-0f49-4714-b9ec-e49b9b1b7638"
      },
      "source": [
        "## Creating an SSP370 dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d20112c0-43ba-48a0-b1ce-a908f154c7a2",
      "metadata": {
        "id": "d20112c0-43ba-48a0-b1ce-a908f154c7a2",
        "outputId": "0e1cb504-c5dd-4436-9bd1-2f301f43672d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.CAMS.CAMS-CSM1-0.ssp370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.CNRM-CERFACS.CNRM-ESM2-1.ssp370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.IPSL.IPSL-CM6A-LR.ssp370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.MIROC.MIROC6.ssp370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.NCAR.CESM2.ssp370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:31: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('lev_bnds')\n",
            "C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_53272\\4128790857.py:34: DeprecationWarning: dropping variables using `drop` is deprecated; use drop_vars.\n",
            "  ds_lev = ds_lev.drop('p')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processamento Concluído: ScenarioMIP.NOAA-GFDL.GFDL-ESM4.ssp370\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Folder where the files are located\n",
        "pasta = 'Medias_nc\\\\50S_20S'\n",
        "\n",
        "# Folder to save the files\n",
        "saves = 'Dataframes_50S_20S'\n",
        "\n",
        "# List the files in the folder\n",
        "arquivos = os.listdir(pasta)\n",
        "\n",
        "# Loop through the files\n",
        "for arquivo in arquivos:\n",
        "    if \"ssp370\" in arquivo:\n",
        "        caminho_arquivo = os.path.join(pasta, arquivo)\n",
        "\n",
        "        # Open the file using xarray\n",
        "        ds = xr.open_dataset(caminho_arquivo)\n",
        "\n",
        "        # Convert Depth to pressure.\n",
        "        ds['p'] = gsw.p_from_z(-ds['lev'], ds['lat'])\n",
        "\n",
        "        # Convert preformed salinity to absolute salinity.\n",
        "        ds['so'] = gsw.SA_from_Sstar(ds['so'], ds['p'], ds['lon'],ds['lat'])\n",
        "\n",
        "        # Select the depth interval from 500 to 1500m\n",
        "        ds_lev = ds.sel(lev=slice(300, 1500))\n",
        "\n",
        "        # Create the volume variable, according to the area for every 5m\n",
        "        ds_lev[\"vol\"] = 5 * ds_lev[\"area\"]\n",
        "\n",
        "        if 'lev_bnds' in ds_lev:\n",
        "            ds_lev = ds_lev.drop('lev_bnds')\n",
        "\n",
        "        if 'p' in ds_lev:\n",
        "            ds_lev = ds_lev.drop('p')\n",
        "\n",
        "        # Create the list for temperature intervals\n",
        "        lista_temp = []\n",
        "        i = -2\n",
        "        lista_temp.append(i)\n",
        "        while round(i, 2) < 20:\n",
        "            i += 0.2\n",
        "            lista_temp.append(round(i, 2))\n",
        "\n",
        "        # Create the list for salinity intervals\n",
        "        lista_sal = []\n",
        "        i=33\n",
        "        lista_sal.append(i)\n",
        "        while round(i, 3) < 37:\n",
        "            i+=0.02\n",
        "            lista_sal.append(round(i, 3))\n",
        "\n",
        "        # Create a dataframe to store\n",
        "        df_final = pd.DataFrame()\n",
        "\n",
        "        df = ds_lev.to_dataframe().dropna().reset_index()\n",
        "\n",
        "        # Apply pd.cut with defined limits\n",
        "        cut_temp = pd.cut(df['thetao'], bins=lista_temp, include_lowest=True)\n",
        "        cut_salin = pd.cut(df['so'], bins=lista_sal, include_lowest=True)\n",
        "\n",
        "        # Group data by category intersections\n",
        "        agrupado = df.groupby([cut_temp, cut_salin])['vol'].sum().reset_index()\n",
        "\n",
        "        # Concatenate my data into a final dataframe\n",
        "        df_final = pd.concat([df_final, agrupado], ignore_index=True)\n",
        "\n",
        "        # Create empty lists\n",
        "        thetao_medias = []\n",
        "        so_medias = []\n",
        "\n",
        "        # Calculate interval averages and add to lists\n",
        "        for _, row in df_final.iterrows():\n",
        "            thetao_medias.append(row['thetao'].mid)\n",
        "            so_medias.append(row['so'].mid)\n",
        "\n",
        "        # Add lists as new columns to df_agrupado\n",
        "        df_final['thetao_media'] = thetao_medias\n",
        "        df_final['so_media'] = so_medias\n",
        "\n",
        "        df_final = df_final[[\"thetao_media\", \"so_media\", \"vol\"]]\n",
        "\n",
        "        # Rename\n",
        "        df_final.rename(columns={\"thetao_media\": \"thetao\", \"so_media\": \"so\"}, inplace=True)\n",
        "\n",
        "        # Extract the base file name (without path)\n",
        "        nome_base = os.path.basename(arquivo)\n",
        "\n",
        "        # Extract the relevant part of the name to use as DataFrame name\n",
        "        nome_partes = nome_base.split('.')\n",
        "        nome_dataframe = '.'.join(nome_partes[0:4])\n",
        "\n",
        "        # Define the output path for the parquet file based on the DataFrame name\n",
        "        caminho_saida = os.path.join(saves, f\"{nome_dataframe}.parquet\")\n",
        "\n",
        "        # Save the DataFrame in parquet format\n",
        "        df_final.to_parquet(caminho_saida)\n",
        "\n",
        "        print('Processing Completed: {}'.format(nome_dataframe))\n",
        "        # Close the xarray dataset\n",
        "        ds.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe98761d-931b-4630-9834-6c19866c027b",
      "metadata": {
        "id": "fe98761d-931b-4630-9834-6c19866c027b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "PyGMT",
      "language": "python",
      "name": "pygmt"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}