{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ed0e24a"
      },
      "source": [
        "This notebook aims to process CMIP6 climate model data for a specific geographical region and time period. The main steps include:\n",
        "\n",
        "1.  **Accessing CMIP6 Catalog**: Connecting to the CMIP6 datastore hosted on Google Cloud to fetch model data.\n",
        "2.  **Reading Model Table**: Loading an Excel file containing information about the models and variables to be processed.\n",
        "3.  **Defining Area of Interest**: Reading a KML file that defines the geographical region for which data will be extracted.\n",
        "4.  **Data Processing and Analysis**: Iterating over the specified models, applying auxiliary functions to:\n",
        "    *   Search for and load model data.\n",
        "    *   Associate grid area with each model.\n",
        "    *   Correct and standardize the time dimension.\n",
        "    *   Rename and standardize coordinates and depth units.\n",
        "    *   Apply a geographical mask to select only the region of interest.\n",
        "    *   Calculate the temporal mean of the data.\n",
        "    *   Vertically interpolate the data to a new depth grid.\n",
        "    *   Calculate the volume (assuming a thickness of 5 units for each interpolated level).\n"
      ],
      "id": "6ed0e24a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc06d03d-b01b-42d8-a9d9-0b8cbf36ffa7",
      "metadata": {
        "tags": [],
        "id": "bc06d03d-b01b-42d8-a9d9-0b8cbf36ffa7",
        "outputId": "1849b618-5348-4d74-c627-4d1b28c10900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
            "Requirement already satisfied: openpyxl in /srv/conda/envs/notebook/lib/python3.9/site-packages (3.1.5)\n",
            "Requirement already satisfied: regionmask in /srv/conda/envs/notebook/lib/python3.9/site-packages (0.12.1)\n",
            "Collecting numpy==1.20.0\n",
            "  Downloading numpy-1.20.0-cp39-cp39-manylinux2010_x86_64.whl (15.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4 MB 799 kB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile in /srv/conda/envs/notebook/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: geopandas>=0.10 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (0.10.2)\n",
            "Requirement already satisfied: xarray>=0.20 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (0.20.1)\n",
            "Requirement already satisfied: pooch>=1.4 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (1.5.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (21.3)\n",
            "Collecting regionmask\n",
            "  Downloading regionmask-0.12.1-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 26.0 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading regionmask-0.11.0-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 38.4 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading regionmask-0.10.0-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 32.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: shapely>=1.7 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=40.4 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (59.2.0)\n",
            "Requirement already satisfied: rasterio>=1.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (1.2.10)\n",
            "Requirement already satisfied: fiona>=1.8 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from geopandas>=0.10->regionmask) (1.8.20)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from geopandas>=0.10->regionmask) (3.2.1)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from geopandas>=0.10->regionmask) (1.3.4)\n",
            "Requirement already satisfied: attrs>=17 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas>=0.10->regionmask) (21.2.0)\n",
            "Requirement already satisfied: certifi in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas>=0.10->regionmask) (2021.10.8)\n",
            "Requirement already satisfied: click>=4.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas>=0.10->regionmask) (7.1.2)\n",
            "Requirement already satisfied: cligj>=0.5 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas>=0.10->regionmask) (0.7.2)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas>=0.10->regionmask) (1.1.1)\n",
            "Requirement already satisfied: six>=1.7 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas>=0.10->regionmask) (1.16.0)\n",
            "Requirement already satisfied: munch in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas>=0.10->regionmask) (2.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from packaging>=21.3->regionmask) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from pandas>=0.25.0->geopandas>=0.10->regionmask) (2.7.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from pandas>=0.25.0->geopandas>=0.10->regionmask) (2021.3)\n",
            "Requirement already satisfied: appdirs in /srv/conda/envs/notebook/lib/python3.9/site-packages (from pooch>=1.4->regionmask) (1.4.4)\n",
            "Requirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.9/site-packages (from pooch>=1.4->regionmask) (2.26.0)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from rasterio>=1.1->regionmask) (1.4.7)\n",
            "Requirement already satisfied: affine in /srv/conda/envs/notebook/lib/python3.9/site-packages (from rasterio>=1.1->regionmask) (2.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from requests->pooch>=1.4->regionmask) (3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from requests->pooch>=1.4->regionmask) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from requests->pooch>=1.4->regionmask) (2.0.0)\n",
            "Installing collected packages: numpy, regionmask\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.0\n",
            "    Uninstalling numpy-2.0.0:\n",
            "      Successfully uninstalled numpy-2.0.0\n",
            "  Attempting uninstall: regionmask\n",
            "    Found existing installation: regionmask 0.12.1\n",
            "    Uninstalling regionmask-0.12.1:\n",
            "      Successfully uninstalled regionmask-0.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymbolic 2021.1 requires pytest>=2.3, which is not installed.\n",
            "ciso 0.1.0 requires cython, which is not installed.\u001b[0m\n",
            "Successfully installed numpy-1.20.0 regionmask-0.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl regionmask numpy==1.20.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a84dd0d6-d512-494b-a3e3-8d7cd93bcf09",
      "metadata": {
        "tags": [],
        "id": "a84dd0d6-d512-494b-a3e3-8d7cd93bcf09"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "import gcsfs\n",
        "import intake\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import cftime\n",
        "import geopandas as gpd\n",
        "import regionmask\n",
        "import re\n",
        "import numpy as np\n",
        "import fiona\n",
        "fiona.drvsupport.supported_drivers['KML'] = 'rw'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a63dc20-96c0-4865-b5e1-4c6a91a27059",
      "metadata": {
        "tags": [],
        "id": "9a63dc20-96c0-4865-b5e1-4c6a91a27059"
      },
      "outputs": [],
      "source": [
        "def rename_coords(ds):\n",
        "    \"\"\"Renames the latitude, longitude, and depth variables to 'lat', 'lon', and 'lev',\n",
        "    respectively, using the coordinate variable names automatically detected in the file.\n",
        "    \"\"\"\n",
        "    # Creates a dictionary with the possible old names for the latitude, longitude, and depth variables\n",
        "    # and their corresponding new names\n",
        "    coord_names = {\n",
        "        'latitude': 'lat', 'nav_lat': 'lat', 'lat': 'lat',\n",
        "        'longitude': 'lon', 'nav_lon': 'lon', 'lon': 'lon',\n",
        "        'olevel': 'lev',\n",
        "        'olevel_bounds': 'lev_bnds'\n",
        "    }\n",
        "    # Iterates over the list of coordinate names present in the file\n",
        "    for coord_name in ds.coords.keys():\n",
        "        # Checks whether the coordinate name matches one of the possible old names\n",
        "        if coord_name in coord_names:\n",
        "            # Renames the coordinate variable using the rename() method\n",
        "            ds = ds.rename({coord_name: coord_names[coord_name]})\n",
        "    # Returns the dataset with the coordinate variables renamed\n",
        "    return ds.copy()\n",
        "\n",
        "# Function to fix the time variable! Some CMIP6 formats for the time variable make it hard to manipulate.\n",
        "def to_360day_monthly(da):\n",
        "    ''' Conversion of the time dimension for climate models.\n",
        "        Function created by Claire Carouge on the CLEX CMS Blog '''\n",
        "    val = da.copy()\n",
        "    time1 = da.time.copy()\n",
        "    for itime in range(val.sizes['time']):\n",
        "        bb = val.time.values[itime].timetuple()\n",
        "        time1.values[itime] = cftime.Datetime360Day(bb[0], bb[1], 16)\n",
        "    val = val.assign_coords({'time': time1})\n",
        "    return val\n",
        "\n",
        "# Function that inserts the area variable into the xarray dataset for volume calculation\n",
        "def assing_area(dic):\n",
        "    pesquisa = {'source_id': dic['source_id'],\n",
        "                'table_id': \"Ofx\",\n",
        "                'variable_id': 'areacello',\n",
        "                'experiment_id': dic['experiment_id'],\n",
        "                'member_id': dic['member_id']}\n",
        "\n",
        "    cat_area = cmip6.search(require_all_on='source_id', **pesquisa)\n",
        "    cat_area = cat_area.to_dataset_dict(aggregate=True,\n",
        "                            storage_options={'token': 'anon'},\n",
        "                            zarr_kwargs={'consolidated': True,\n",
        "                            'decode_times': True,\n",
        "                            'use_cftime': True})\n",
        "\n",
        "    # If nothing is returned, return None\n",
        "    if len(cat_area) == 0:\n",
        "        return None\n",
        "\n",
        "    # Selects the grid-cell area from grid 'gn'\n",
        "    for key in list(cat_area.keys()):\n",
        "        if \".gn\" in key:\n",
        "            ds_area = cat_area[key]\n",
        "\n",
        "    ds_area = ds_area.squeeze().drop([\"member_id\", \"dcpp_init_year\"])\n",
        "    ds_select_area = ds_area[\"areacello\"]\n",
        "    return rename_coords(ds_select_area)\n",
        "\n",
        "# Function that converts depth from centimeters to meters\n",
        "def depth_m(ds):\n",
        "    if \"lev\" in ds:\n",
        "        if \"units\" in ds[\"lev\"].attrs:\n",
        "            units = ds[\"lev\"].units.lower()\n",
        "            if units == \"cm\" or units == \"centimeters\":\n",
        "                ds[\"lev\"] = ds[\"lev\"] / 100\n",
        "                ds[\"lev\"].attrs[\"units\"] = \"m\"\n",
        "    return ds\n",
        "\n",
        "# Renames the level_bnds variable\n",
        "def rename_lev_bnds(ds):\n",
        "    if 'axis_nbounds' in ds.dims:\n",
        "        ds = ds.rename_dims({'axis_nbounds': 'bnds'})\n",
        "    elif 'd2' in ds.dims:\n",
        "        ds = ds.rename_dims({'d2': 'bnds'})\n",
        "\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12fd5be3-141e-472c-ad95-069ae2640536",
      "metadata": {
        "tags": [],
        "id": "12fd5be3-141e-472c-ad95-069ae2640536"
      },
      "outputs": [],
      "source": [
        "#Accesses the CMIP6 metadata set hosted on Google Cloud.\n",
        "cmip6 = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc4b63a5-bfb0-4a8b-b34d-1742ccf1c0dd",
      "metadata": {
        "tags": [],
        "id": "dc4b63a5-bfb0-4a8b-b34d-1742ccf1c0dd"
      },
      "outputs": [],
      "source": [
        "# Reading my Model Table.\n",
        "# Check the path, in my Jupyter Lab everything is in the same folder.\n",
        "df = pd.read_excel(\"Tabela_Modelos/Tabela_Modelos.xlsx\", sheet_name=1)\n",
        "df = df.rename(columns = lambda x : x.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04afd12b-e026-4d96-99ad-f7d791925f40",
      "metadata": {
        "tags": [],
        "id": "04afd12b-e026-4d96-99ad-f7d791925f40"
      },
      "outputs": [],
      "source": [
        "# Performs my search according to my Model Table\n",
        "pesquisas = []\n",
        "for index, row in df.iterrows():\n",
        "    pesquisa = {'source_id': row['source_id'],\n",
        "                'table_id': row['table_id'],\n",
        "                'variable_id': row['variable_id'].split(', '),\n",
        "                'experiment_id': row['experiment_id'],\n",
        "                'member_id': row['member_id']}\n",
        "    pesquisas.append(pesquisa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f502a357-fa8b-4600-a5c1-95569c2a4f4f",
      "metadata": {
        "tags": [],
        "id": "f502a357-fa8b-4600-a5c1-95569c2a4f4f"
      },
      "outputs": [],
      "source": [
        "gdf = gpd.read_file('Area_Projeto/50S_20S/50S_20S.kml', driver=\"KML\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb9401c-7f1a-4550-b4fe-2cb20fde540a",
      "metadata": {
        "id": "fdb9401c-7f1a-4550-b4fe-2cb20fde540a",
        "outputId": "abd948dc-8e39-48ff-866f-f98abd50c9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
            "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [2/2 00:02<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "to_dataset_dict() got an unexpected keyword argument 'xarray_open_kwargs'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_586/2153200915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m#Area do modelo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mds_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massing_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpesquisa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mds_area\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_586/2772978431.py\u001b[0m in \u001b[0;36massing_area\u001b[0;34m(dic)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mcat_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmip6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequire_all_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'source_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpesquisa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     cat_area = cat_area.to_dataset_dict(aggregate=True,\n\u001b[0m\u001b[1;32m     44\u001b[0m                             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'anon'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                             xarray_open_kwargs={'consolidated': True,\n",
            "\u001b[0;31mTypeError\u001b[0m: to_dataset_dict() got an unexpected keyword argument 'xarray_open_kwargs'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Defines the initial time slice\n",
        "time_inicio = 1981\n",
        "time_fim = 2010\n",
        "\n",
        "# Iterates to select my area of interest for all Models\n",
        "for pesquisa in pesquisas:\n",
        "    cat = cmip6.search(require_all_on='source_id', **pesquisa)\n",
        "    cat = cat.to_dataset_dict(aggregate=True,\n",
        "                            storage_options={'token': 'anon'},\n",
        "                            zarr_kwargs={'consolidated': True,\n",
        "                            'decode_times': True,\n",
        "                            'use_cftime': True})\n",
        "\n",
        "    for key in list(cat.keys()):\n",
        "        if \".gn\" in key:\n",
        "            ds = cat[key]\n",
        "\n",
        "            # Model area.\n",
        "            ds_area = assing_area(pesquisa)\n",
        "\n",
        "            if ds_area is None:\n",
        "                continue\n",
        "\n",
        "            # Correcting times. Uses the previously defined function to correct the time variable\n",
        "            ds = to_360day_monthly(ds)\n",
        "\n",
        "            # Renames variables to standardize names across models\n",
        "            ds = rename_coords(ds)\n",
        "\n",
        "            # Renames lev_bnds\n",
        "            ds = rename_lev_bnds(ds)\n",
        "\n",
        "            # Converts depth units to meters\n",
        "            ds = depth_m(ds)\n",
        "\n",
        "            # Deletes variables present in xarray that are not of interest to us.\n",
        "            ds_drop = ds.drop([v for v in ds.coords if v not in ['lat', 'lon', 'time', 'lev', 'lev_bnds']])\n",
        "\n",
        "            # Adds the area variable to my xarray\n",
        "            ds_with_area = ds_drop.assign_coords(area=ds_area)\n",
        "\n",
        "            # Defines a time slice\n",
        "            ds_time = ds_with_area.sel(time=slice(str(time_inicio), str(time_fim)))\n",
        "\n",
        "            # Squeezes to remove unimportant dimensions\n",
        "            ds_time = ds_time.squeeze()\n",
        "\n",
        "            # Converts the GeoDataFrame to a region mask object\n",
        "            mask = regionmask.mask_geopandas(gdf, ds_time['lon'], ds_time['lat'])\n",
        "\n",
        "            # Applies the mask to the dataset\n",
        "            ds_masked = ds_time.where(mask==mask, drop=True)\n",
        "\n",
        "            # Temporal Mean\n",
        "            ds_mean = ds_masked.mean(dim='time').compute()\n",
        "\n",
        "            # Levels to interpolate\n",
        "            new_levels = np.arange(0, 3000, 5)\n",
        "\n",
        "            # Vertical interpolation\n",
        "            ds_interp = ds_mean.interp(lev=new_levels)\n",
        "\n",
        "            # Calculates the volume\n",
        "            ds_interp[\"vol\"] = 5 * ds_interp[\"area\"]\n",
        "\n",
        "            ds_interp.to_netcdf(\"Medias_nc/50S_20S/{}.nc\".format(key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa8fb2cb-6380-4f11-a3aa-755935b7f094",
      "metadata": {
        "id": "fa8fb2cb-6380-4f11-a3aa-755935b7f094"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}