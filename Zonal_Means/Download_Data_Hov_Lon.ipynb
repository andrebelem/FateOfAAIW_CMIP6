{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### This notebook downloads the files needed to compute zonal-mean differences (longitude averages) for the study region. It interpolates the data to the World Ocean Atlas (WOA) depth levels in case a comparison with observational data is desired, although this step is optional. The notebook computes the zonal mean while preserving the time dimension.\n",
        "\n",
        "####This workflow can be done in two ways:\n",
        "\n",
        "#### 1. Download only the subset for the study region, as implemented here, and compute the zonal mean directly; or\n",
        "\n",
        "#### 2. Download the full model data, extract the study region afterwards (preserving time, longitude, and latitude), and compute the zonal mean during the figure-generation stage."
      ],
      "metadata": {
        "id": "xFnE--0NVbz0"
      },
      "id": "xFnE--0NVbz0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27dfe651-ef14-4cc6-8954-e63337618722",
      "metadata": {
        "tags": [],
        "id": "27dfe651-ef14-4cc6-8954-e63337618722",
        "outputId": "0cdabc5e-e58d-409d-e383-6aa229cc81eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
            "Requirement already satisfied: geopandas in /srv/conda/envs/notebook/lib/python3.9/site-packages (0.10.2)\n",
            "Collecting regionmask\n",
            "  Downloading regionmask-0.12.1-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 7.4 MB/s eta 0:00:011\n",
            "\u001b[?25hCollecting openpyxl\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[K     |████████████████████████████████| 250 kB 11.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy==1.20.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (1.20.0)\n",
            "Requirement already satisfied: shapely>=1.6 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from geopandas) (1.8.0)\n",
            "Requirement already satisfied: fiona>=1.8 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from geopandas) (1.8.20)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from geopandas) (3.2.1)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from geopandas) (1.3.4)\n",
            "Requirement already satisfied: attrs>=17 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (21.2.0)\n",
            "Requirement already satisfied: certifi in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (2021.10.8)\n",
            "Requirement already satisfied: click>=4.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
            "Requirement already satisfied: cligj>=0.5 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
            "Requirement already satisfied: six>=1.7 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (1.16.0)\n",
            "Requirement already satisfied: munch in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
            "Requirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.9/site-packages (from fiona>=1.8->geopandas) (59.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from pandas>=0.25.0->geopandas) (2.7.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from pandas>=0.25.0->geopandas) (2021.3)\n",
            "Collecting et-xmlfile\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (21.3)\n",
            "Requirement already satisfied: rasterio>=1.2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (1.2.10)\n",
            "Collecting regionmask\n",
            "  Downloading regionmask-0.11.0-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 19.0 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading regionmask-0.10.0-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 52.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pooch>=1.2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (1.5.2)\n",
            "Requirement already satisfied: xarray>=0.15 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from regionmask) (0.20.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from packaging>=21.3->regionmask) (3.0.6)\n",
            "Requirement already satisfied: appdirs in /srv/conda/envs/notebook/lib/python3.9/site-packages (from pooch>=1.2->regionmask) (1.4.4)\n",
            "Requirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.9/site-packages (from pooch>=1.2->regionmask) (2.26.0)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from rasterio>=1.2->regionmask) (1.4.7)\n",
            "Requirement already satisfied: affine in /srv/conda/envs/notebook/lib/python3.9/site-packages (from rasterio>=1.2->regionmask) (2.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from requests->pooch>=1.2->regionmask) (1.26.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from requests->pooch>=1.2->regionmask) (3.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from requests->pooch>=1.2->regionmask) (2.0.0)\n",
            "Installing collected packages: et-xmlfile, regionmask, openpyxl\n",
            "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5 regionmask-0.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install geopandas regionmask openpyxl numpy==1.20.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a3023fd",
      "metadata": {
        "tags": [],
        "id": "6a3023fd"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "import gcsfs\n",
        "import intake\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import cftime\n",
        "import geopandas as gpd\n",
        "import regionmask\n",
        "import re\n",
        "import numpy as np\n",
        "import fiona\n",
        "import xesmf as xe\n",
        "import gsw\n",
        "fiona.drvsupport.supported_drivers['KML'] = 'rw'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4293a032",
      "metadata": {
        "tags": [],
        "id": "4293a032"
      },
      "outputs": [],
      "source": [
        "#WOA levels for comparison:\n",
        "new_levels = [0.00e+00, 5.00e+00, 1.00e+01, 1.50e+01, 2.00e+01, 2.50e+01,\n",
        "       3.00e+01, 3.50e+01, 4.00e+01, 4.50e+01, 5.00e+01, 5.50e+01,\n",
        "       6.00e+01, 6.50e+01, 7.00e+01, 7.50e+01, 8.00e+01, 8.50e+01,\n",
        "       9.00e+01, 9.50e+01, 1.00e+02, 1.25e+02, 1.50e+02, 1.75e+02,\n",
        "       2.00e+02, 2.25e+02, 2.50e+02, 2.75e+02, 3.00e+02, 3.25e+02,\n",
        "       3.50e+02, 3.75e+02, 4.00e+02, 4.25e+02, 4.50e+02, 4.75e+02,\n",
        "       5.00e+02, 5.50e+02, 6.00e+02, 6.50e+02, 7.00e+02, 7.50e+02,\n",
        "       8.00e+02, 8.50e+02, 9.00e+02, 9.50e+02, 1.00e+03, 1.05e+03,\n",
        "       1.10e+03, 1.15e+03, 1.20e+03, 1.25e+03, 1.30e+03, 1.35e+03,\n",
        "       1.40e+03, 1.45e+03, 1.50e+03, 1.55e+03, 1.60e+03, 1.65e+03,\n",
        "       1.70e+03, 1.75e+03, 1.80e+03, 1.85e+03, 1.90e+03, 1.95e+03,\n",
        "       2.00e+03, 2.10e+03, 2.20e+03, 2.30e+03, 2.40e+03, 2.50e+03,\n",
        "       2.60e+03, 2.70e+03, 2.80e+03, 2.90e+03, 3.00e+03, 3.10e+03,\n",
        "       3.20e+03, 3.30e+03, 3.40e+03, 3.50e+03, 3.60e+03, 3.70e+03,\n",
        "       3.80e+03, 3.90e+03, 4.00e+03, 4.10e+03, 4.20e+03, 4.30e+03,\n",
        "       4.40e+03, 4.50e+03, 4.60e+03, 4.70e+03, 4.80e+03, 4.90e+03,\n",
        "       5.00e+03, 5.10e+03, 5.20e+03, 5.30e+03, 5.40e+03, 5.50e+03]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c396be1",
      "metadata": {
        "tags": [],
        "id": "9c396be1"
      },
      "outputs": [],
      "source": [
        "def rename_coords(ds):\n",
        "    \"\"\"Renames latitude, longitude, and depth variables to 'lat', 'lon', and 'lev',\n",
        "    respectively, using automatically found coordinate variable names in the file.\n",
        "    \"\"\"\n",
        "    # Creates a dictionary with possible old names for latitude, longitude, and depth variables\n",
        "    # and their corresponding new names\n",
        "    coord_names = {\n",
        "        'latitude': 'lat', 'nav_lat': 'lat', 'lat': 'lat',\n",
        "        'longitude': 'lon', 'nav_lon': 'lon', 'lon': 'lon',\n",
        "        'olevel': 'lev',\n",
        "        'olevel_bounds': 'lev_bnds'\n",
        "    }\n",
        "    # Iterates over the list of coordinate names present in the file\n",
        "    for coord_name in ds.coords.keys():\n",
        "        # Checks if the coordinate name corresponds to one of the possible old names for coordinate variables\n",
        "        if coord_name in coord_names:\n",
        "            # Renames the coordinate variable using the rename() method\n",
        "            ds = ds.rename({coord_name: coord_names[coord_name]})\n",
        "    # Returns the Dataset with renamed coordinate variables\n",
        "    return ds.copy()\n",
        "\n",
        "#Function to fix the time variable! Because some time formats available in CMIP6 make it difficult to manipulate.\n",
        "def to_360day_monthly(da):\n",
        "    ''' Conversion of the time dimension of climate models.\n",
        "        Function created by Claire Carouge in the CLEX CMS Blog'''\n",
        "    val = da.copy()\n",
        "    time1 = da.time.copy()\n",
        "    for itime in range(val.sizes['time']):\n",
        "        bb = val.time.values[itime].timetuple()\n",
        "        time1.values[itime] = cftime.Datetime360Day(bb[0],bb[1],16)\n",
        "    val = val.assign_coords({'time':time1})\n",
        "    return val\n",
        "\n",
        "#Function that converts depth from centimeters to meters.\n",
        "def depth_m(ds):\n",
        "    if \"lev\" in ds:\n",
        "        if \"units\" in ds[\"lev\"].attrs:\n",
        "            units = ds[\"lev\"].attrs[\"units\"].lower()\n",
        "            if units == \"cm\" or units == \"centimeters\":\n",
        "                ds[\"lev\"] = ds[\"lev\"] / 100\n",
        "                ds[\"lev\"].attrs[\"units\"] = \"m\"\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a72e3e3c",
      "metadata": {
        "tags": [],
        "id": "a72e3e3c"
      },
      "outputs": [],
      "source": [
        "#Accesses the CMIP6 metadata set hosted on Google Cloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3f82d1f",
      "metadata": {
        "id": "b3f82d1f"
      },
      "outputs": [],
      "source": [
        "#Reading my Model Table.\n",
        "#Check the path, in my jupyter lab everything is in the same folder.\n",
        "df = pd.read_excel(\"Tabela_Modelos/Tabela_Modelos.xlsx\", sheet_name='SSP585')\n",
        "df = df.rename(columns = lambda x : x.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23acf55d",
      "metadata": {
        "tags": [],
        "id": "23acf55d"
      },
      "outputs": [],
      "source": [
        "gdf = gpd.read_file('Area_Projeto/Regiao_Juntas/Regiao_Juntas.shp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1074b7d",
      "metadata": {
        "tags": [],
        "id": "f1074b7d"
      },
      "outputs": [],
      "source": [
        "#Performs my search according to my Model Table\n",
        "pesquisas = []\n",
        "for index, row in df.iterrows():\n",
        "    pesquisa = {'source_id': row['source_id'],\n",
        "                'table_id': row['table_id'],\n",
        "                'variable_id': row['variable_id'].split(', '),\n",
        "                'experiment_id': row['experiment_id'],\n",
        "                'member_id': row['member_id']}\n",
        "    pesquisas.append(pesquisa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "706118c4-dc2b-447d-9a45-b37616b9cd1a",
      "metadata": {
        "id": "706118c4-dc2b-447d-9a45-b37616b9cd1a",
        "outputId": "649c0631-08b3-44f6-c181-100214a95243"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'source_id': 'CESM2',\n",
              "  'table_id': 'Omon',\n",
              "  'variable_id': ['thetao', 'so'],\n",
              "  'experiment_id': 'ssp585',\n",
              "  'member_id': 'r10i1p1f1'},\n",
              " {'source_id': 'MIROC6',\n",
              "  'table_id': 'Omon',\n",
              "  'variable_id': ['thetao', 'so'],\n",
              "  'experiment_id': 'ssp585',\n",
              "  'member_id': 'r1i1p1f1'},\n",
              " {'source_id': 'GFDL-ESM4',\n",
              "  'table_id': 'Omon',\n",
              "  'variable_id': ['thetao', 'so'],\n",
              "  'experiment_id': 'ssp585',\n",
              "  'member_id': 'r1i1p1f1'}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filters only the desired models\n",
        "modelos_desejados = ['MIROC6', 'CESM2', 'GFDL-ESM4']\n",
        "pesquisas = [p for p in pesquisas if p['source_id'] in modelos_desejados]\n",
        "\n",
        "pesquisas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ced63e",
      "metadata": {
        "tags": [],
        "id": "71ced63e",
        "outputId": "475a49ef-a7ad-4708-d018-3bd0f0e7fc45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
            "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [1/1 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/srv/conda/envs/notebook/lib/python3.9/site-packages/xarray/core/indexing.py:1233: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
            "chunk and silence this warning, set the option\n",
            "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
            "    ...     array[indexer]\n",
            "\n",
            "To avoid creating the large chunks, set the option\n",
            "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
            "    ...     array[indexer]\n",
            "  value = value[(slice(None),) * axis + (subkey,)]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "for pesquisa in pesquisas:\n",
        "    cat = cmip6.search(require_all_on='source_id', **pesquisa)\n",
        "    cat = cat.to_dataset_dict(aggregate=True,\n",
        "                              storage_options={'token': 'anon'},\n",
        "                              zarr_kwargs={'consolidated': True,\n",
        "                                                 'decode_times': True,\n",
        "                                                 'use_cftime': True})\n",
        "\n",
        "    # Variable to store the dataset\n",
        "    ds = None\n",
        "\n",
        "    # Iterate over the list keys\n",
        "    for key in list(cat.keys()):\n",
        "        # Check if the key ends with \"gr\"\n",
        "        if key.endswith(\"gr\"):\n",
        "            ds = cat[key]\n",
        "            break  # If \"gr\" is found, no need to continue searching\n",
        "\n",
        "    # If \"gr\" was not found, ds will retain the last value assigned in the loop\n",
        "    # If no value ends with \"gr\", ds will retain the last value ending with \"gn\"\n",
        "    if ds is None:\n",
        "        for key in list(cat.keys()):\n",
        "            if key.endswith(\"gn\"):\n",
        "                ds = cat[key]\n",
        "                break  # If \"gn\" is found, no need to continue searching\n",
        "\n",
        "    #Converts time to the correct format.\n",
        "    ds = ds[[\"thetao\", \"so\"]].squeeze()\n",
        "\n",
        "    #Fixes depth\n",
        "    ds = depth_m(ds)\n",
        "\n",
        "    if \"gn\" in ds.grid_label:\n",
        "        ds_out = xr.Dataset(\n",
        "            {\n",
        "                \"lat\" : ([\"lat\"], np.arange(-90, 90, 1.0)),\n",
        "                \"lon\" : ([\"lon\"], np.arange(-180, 180, 1.0)),\n",
        "            }\n",
        "        )\n",
        "\n",
        "        regridder = xe.Regridder(ds, ds_out, \"bilinear\", ignore_degenerate=True, periodic=True)\n",
        "        ds_out = regridder(ds, keep_attrs = True)\n",
        "\n",
        "    else:\n",
        "        ds_out = ds\n",
        "\n",
        "    #Renames olevel to level\n",
        "    ds_out = rename_coords(ds_out)\n",
        "\n",
        "    #Pressure from depth\n",
        "    ds_out[\"press\"] = gsw.p_from_z(-ds_out.lev, ds_out.lat)\n",
        "\n",
        "    #Transforms preformed salinity to absolute salinity\n",
        "    ds_out[\"sa\"] = gsw.SA_from_Sstar(ds_out.so, ds_out.press ,ds_out.lon, ds_out.lat)\n",
        "\n",
        "    # Vertical interpolation using linear interpolation\n",
        "    ds_interp = ds_out.interp(lev=new_levels, method='linear')\n",
        "\n",
        "    #Converts the GeoDataFrame to a region mask object\n",
        "    mask = regionmask.mask_geopandas(gdf, ds_interp['lon'], ds_interp['lat'])\n",
        "\n",
        "    #Applies the mask to the dataset\n",
        "    ds_masked = ds_interp.where(mask==mask, drop=True)\n",
        "\n",
        "    #Calculates the mean for longitude\n",
        "    ds_masked = ds_masked.mean(dim='lon')\n",
        "\n",
        "    #Saves the netcdf\n",
        "    ds_masked.to_netcdf(\"{}.nc\".format(key))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}